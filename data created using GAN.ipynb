{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcSme09O6FBDSWkml+2kA0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayali19-cell/Dataset/blob/main/data%20created%20using%20GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the generator\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(100,)))  # Input dimension is 100 (latent space)\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(784, activation='tanh'))  # Output dimension is 784 (28x28 flattened)\n",
        "    return model\n",
        "\n",
        "# Define the discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(784,)))  # Input dimension is 784 (28x28 flattened)\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(negative_slope=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define the GAN\n",
        "def build_gan(generator, discriminator):\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
        "    return model"
      ],
      "metadata": {
        "id": "eKHklygoy545"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data using the GAN\n",
        "def generate_data(generator, num_samples):\n",
        "    latent_dim = 100  # Dimension of the latent space\n",
        "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "    generated_data = generator.predict(noise)\n",
        "    return generated_data\n",
        "\n",
        "# Build and compile models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "gan = build_gan(generator, discriminator)"
      ],
      "metadata": {
        "id": "B-nmDv1bzBES"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights if available (optional)\n",
        "# generator.load_weights('path_to_generator_weights.h5')\n",
        "# discriminator.load_weights('path_to_discriminator_weights.h5')\n",
        "\n",
        "# Generate synthetic data\n",
        "num_samples = 10000  # Number of samples to generate\n",
        "generated_data = generate_data(generator, num_samples)\n",
        "\n",
        "# Rescale data from [-1, 1] to [0, 1] if needed\n",
        "generated_data = (generated_data + 1) / 2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmGWggb-zBoy",
        "outputId": "9ccf1d67-457e-4aa3-866b-dffdb0e8184a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset to a CSV file\n",
        "# Flatten the data if you want to save it as a CSV (each row is a sample)\n",
        "generated_data_flat = generated_data.reshape(num_samples, -1)\n",
        "df = pd.DataFrame(generated_data_flat)\n",
        "df.to_csv('gan_generated_data.csv', index=False)\n",
        "\n",
        "print(\"Synthetic dataset generated and saved to 'gan_generated_data.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv62rJ9ezE9x",
        "outputId": "55ded8cf-8341-4110-f56c-58a3ad068c55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset generated and saved to 'gan_generated_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-qpraFnzIno"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}